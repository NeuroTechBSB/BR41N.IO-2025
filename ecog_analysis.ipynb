{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJuizHKuWsq2RIVu+TWsoT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeuroTechBSB/BR41N.IO-2025/blob/main/ecog_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing some suggested pipelines\n",
        "\n",
        "# Library used to return all file paths names that match a specific pattern (helps to open files in a chosen directory)\n",
        "from glob import glob # help using glob: https://builtin.com/software-engineering-perspectives/glob-in-python\n",
        "\n",
        "# MNE lybrary to handle ECoG data\n",
        "!pip install mne\n",
        "from mne_bids import BIDSPath, read_raw_bids\n",
        "from mne.viz import plot_alignment, snapshot_brain_montage\n",
        "\n",
        "# Usefull python libraries to do data analysis/visualizations\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Keras is a deep learning API capable of running on top of TensorFlow\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "# Library for machine learning and artificial intelligence\n",
        "import tensorflow as tf\n",
        "\n",
        "# Library for machine learning\n",
        "from sklearn import preprocessing, model_selection"
      ],
      "metadata": {
        "id": "xYANgdOZc5YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading the data files locally in the Google Drive space\n",
        "from google.colab import files\n",
        "files.upload() #this will prompt you to upload a file locally into the Google Drive (temporally for the session)\n",
        "\n",
        "## Alternatively (if want to use a already downloaded file in Google Drive):\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !cp /content/drive/MyDrive/FILE.zip /content\n",
        "# %%capture\n",
        "# !unzip /content/FILE.zip -d data\n"
      ],
      "metadata": {
        "id": "m1evwVl8YpdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usefull functions (that I know and I think can be useful for this analysis, though not in the pipeline rn)\n",
        "\n",
        "!unzip FILE.zip # Unzipping a FILE.zip\n",
        "!pwd # checking currently folder\n",
        "!ls # to know which files are located in a directory\n",
        "%cd # perminantly and explictly change the current path\n",
        "!cd # command ONLY temporarily changes the current path during the one line shell script is running. After that, the IPython intepreter will inplictly change back to the ‘original’ directory\n",
        "!mkdir # make a new directory (ex: !mkdir /content/name_directory)\n",
        "files = os.listdir('FILE') # returns a list containing the names of the files within the given directory\n",
        "print(FILE) # visualize a file\n",
        "print(type(FILE)) # visualize a file type/extension\n",
        "FILE.head()\n",
        "\n",
        "# set search path and glob for files\n",
        "# here we want to look for csv files in the input directory\n",
        "path = 'input'\n",
        "files = glob.glob(path + '/*.csv')\n",
        "\n",
        "df = pd.read_csv(r'FILE.csv') # to read a .csv file\n",
        "print(df)\n",
        "\n",
        "df = (df - df.mean()) / df.std() # to normalize data\n"
      ],
      "metadata": {
        "id": "Hk-1Oll_Yrsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Loading and pre-processing the data\n",
        "# Using as references:\n",
        " # (1) https://mne.tools/stable/auto_tutorials/clinical/30_ecog.html  (for the MNE-related documentation for processing ECoG)\n",
        " # (2) https://github.com/talhaanwarch/youtube-tutorials/blob/main/BCI_Competition_IV.ipynb  (for some of the pre-processing steps)\n",
        "\n",
        "########## verify the information of the stimulus in our project (this example is using a epilepsy dataset, so we need to adapt it to what we have)\n",
        "# first define the bids path. This will create the structure to organize the dataset info\n",
        "bids_path = BIDSPath(\n",
        "    root=bids_root,\n",
        "    subject=\"pt1\",\n",
        "    session=\"presurgery\",\n",
        "    task=\"ictal\",\n",
        "    datatype=\"ieeg\",\n",
        "    extension=\".vhdr\",\n",
        ")\n",
        "\n",
        "# Then we'll use it to load in the sample dataset. This function changes the units of some channels, so we suppress a related warning here by using verbose='error'.\n",
        "raw = read_raw_bids(bids_path=bids_path, verbose=\"error\")\n",
        "\n",
        "# Pick only the ECoG channels, removing the EKG channels\n",
        "raw.pick(picks=\"ecog\")\n",
        "\n",
        "# Load the data\n",
        "raw.load_data()\n",
        "\n",
        "# Check for events info\n",
        "events = mne.events_from_annotations(raw)\n",
        "\n",
        "# Remove line frequency interference\n",
        "raw.notch_filter([60], trans_bandwidth=3) # verify if the power line frequency on the dataset is 60Hz or 50Hz (it depends on the country the data was recorded)\n",
        "\n",
        "# drop bad channels\n",
        "raw.drop_channels(raw.info[\"bads\"])\n",
        "\n",
        "# the coordinate frame of the montage\n",
        "montage = raw.get_montage()\n",
        "print(montage.get_positions()[\"coord_frame\"])\n",
        "\n",
        "# add fiducials to montage\n",
        "montage.add_mni_fiducials(subjects_dir) # subjects_dir = location of the subject file\n",
        "\n",
        "# now with fiducials assigned, the montage will be properly converted to \"head\" which is what MNE requires internally (this is the coordinate\n",
        "# system with the origin between LPA and RPA whereas MNI has the origin at the posterior commissure)\n",
        "raw.set_montage(montage)\n",
        "\n",
        "# Make a 25 second epoch that spans before and after the stimulus onset ########## verify the time of the stimulus in our project\n",
        "epoch_length = 25  # seconds\n",
        "epochs = mne.Epochs(\n",
        "    raw,\n",
        "    event_id=\"onset\",\n",
        "    tmin=13,\n",
        "    tmax=13 + epoch_length,\n",
        "    baseline=None,\n",
        ")\n",
        "# Make evoked from the one epoch and resample\n",
        "evoked = epochs.average().resample(200)\n",
        "del epochs\n",
        "\n",
        "# Check epochs shape\n",
        "epochs.get_data().shape\n",
        "\n",
        "# Creating evoked potentials (can be useful)\n",
        "evoked_stimulus = epochs['Stimulus'].average()\n"
      ],
      "metadata": {
        "id": "YktpSxCdxYXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suggestion for a SVM classification model (YET TO ADAPT TO THE DATASET OF THE PROJECT).\n",
        "# Using as references:\n",
        " # (1) https://keras.io/examples/timeseries/eeg_signal_classification/   (using only some useful functions from this pipeine)\n",
        " # (2) https://www.kaggle.com/code/oliverright/eeg-brain-signals-emotion-classification   (using only some useful functions from this pipeine)\n",
        " # (3) https://www.kaggle.com/code/parhammostame/eeg-eye-state-classification-using-kernel-svm  (using the SVM model proposed)\n",
        "\n",
        "print(FILE[\"label\"].unique(), \"\\n\") # Show the unique labels of the dataset\n",
        "print(len(FILE[\"label\"].unique()), \"\\n\") # Show how much of unique labels is within the dataset\n",
        "\n",
        "# separate targets so you can preprocess the EEG data easily ##### ADAPT\n",
        "Y = df['eyeDetection']\n",
        "print( Y.shape )\n",
        "X = df.drop(columns='eyeDetection')\n",
        "print( X.shape )\n",
        "X.head()\n",
        "\n",
        "###### train and test a Kernel SVM ################3\n",
        "\n",
        "# train an SVM to classify\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# split train test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=48, test_size=0.2, stratify=Y, shuffle=True)\n",
        "\n",
        "# Showing how many data in the test and in the training group\n",
        "print(\n",
        "    f\"Length of x_train : {len(x_train)}\\nLength of x_test : {len(x_test)}\\nLength of y_train : {len(y_train)}\\nLength of y_test : {len(y_test)}\"\n",
        ")\n",
        "\n",
        "# normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# train with grid search\n",
        "svc = SVC()\n",
        "parameters = {'gamma': [0.1, 1, 10], 'C': [0.1, 1, 10]}\n",
        "clf = GridSearchCV(svc, parameters)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# predict labels\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# extract accuracy (r2 score)\n",
        "results = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# print score\n",
        "print( 'Score is: ' + str( results ) )\n",
        "print( 'Best params for the kernel SVM is: ' + str(clf.best_params_) )\n",
        "\n",
        "##### Confusion matrix ##############3\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# confusion matrix estimation\n",
        "conf = confusion_matrix(y_test, y_pred, normalize='true')\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(conf, annot=True, cmap='seismic', annot_kws={'fontsize':18})\n",
        "_ = plt.title( 'AUC score: ' + str(round(results, 2) ), fontsize=15)\n",
        "_ = plt.xticks(ticks=[0.5, 1.5], labels=['Eyes-closed', 'Eyes-open'])\n",
        "_ = plt.yticks(ticks=[0.5, 1.5], labels=['Eyes-closed', 'Eyes-open'])\n",
        "_ = plt.ylabel('True label', fontsize=15)\n",
        "_ = plt.xlabel('Predicted label', fontsize=15)"
      ],
      "metadata": {
        "id": "zpa4qkFn4Yif"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}